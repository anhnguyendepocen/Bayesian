Bayesian Data AnalysisThird Edition
CHAPMAN & HALL/CRCTexts in Statistical Science SeriesSeries EditorsFrancesca Dominici, Harvard School of Public Health, USA Julian J. Faraway, University of Bath, UKMartin Tanner, Northwestern University, USAJim Zidek, University of British Columbia, CanadaAnalysis of Failure and Survival DataP. J. SmithThe Analysis of Time Series: An Introduction, Sixth EditionC. ChatfieldApplied Bayesian Forecasting and Time Series AnalysisA. Pole, M. West, and J. HarrisonApplied Categorical and Count Data AnalysisW. Tang, H. He, and X.M. TuApplied Nonparametric Statistical Methods, Fourth EditionP. Sprent and N.C. SmeetonData Driven Statistical MethodsP. SprentDecision Analysis: A Bayesian ApproachJ.Q. SmithDesign and Analysis of Experiments with SASJ. LawsonElementary Applications of Probability Theory, Second EditionH.C. TuckwellElements of SimulationB.J.T. MorganEpidemiology: Study Design and Data Analysis, Third EditionM. WoodwardEssential Statistics, Fourth EditionD.A.G. ReesExercises and Solutions in Statistical TheoryL.L. Kupper, B.H. Neelon, and S.M. O’BrienExercises and Solutions in Biostatistical TheoryL.L. Kupper, B.H. Neelon, and S.M. O’BrienExtending the Linear Model with R: Generalized Linear, Mixed Effects and Nonparametric Regression ModelsJ.J. FarawayA First Course in Linear Model TheoryN. Ravishanker and D.K. DeyGeneralized Additive Models: An Introduction with R S.WoodGeneralized Linear Mixed Models:Modern Concepts, Methods and Applications W. W. StroupGraphics for Statistics and Data Analysis with RK.J. KeenInterpreting Data: A First Course in StatisticsA.J.B. AndersonIntroduction to General and Generalized Linear ModelsH. Madsen and P. ThyregodApplied Statistics: Handbook of GENSTAT AnalysesE.J. Snell and H. SimpsonApplied Statistics: Principles and ExamplesD.R. Cox and E.J. SnellApplied Stochastic Modelling, Second EditionB.J.T. MorganBayesian Data Analysis, Third EditionA. Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson, A. Vehtari, and D.B. RubinBayesian Ideas and Data Analysis: An Introduction for Scientists and Statisticians R. Christensen, W. Johnson, A. Branscum, and T.E. HansonBayesian Methods for Data Analysis, Third EditionB.P. Carlin and T.A. LouisBeyond ANOVA: Basics of Applied StatisticsR.G. Miller, Jr.The BUGS Book: A Practical Introduction to Bayesian AnalysisD. Lunn, C. Jackson, N. Best, A. Thomas, and D. SpiegelhalterA Course in Categorical Data AnalysisT.LeonardA Course in Large Sample TheoryT.S. Ferguson
An Introduction to Generalized Linear Models, Third Edition A.J. Dobson and A.G. BarnettIntroduction to Multivariate AnalysisC. Chatfield and A.J. CollinsIntroduction to Optimization Methods and Their Applications in StatisticsB.S. EverittIntroduction to Probability with RK. BaclawskiIntroduction to Randomized Controlled Clinical Trials, Second EditionJ.N.S. MatthewsIntroduction to Statistical Inference and Its Applications with RM.W. TrossetIntroduction to Statistical Limit TheoryA.M. PolanskyIntroduction to Statistical Methods for Clinical TrialsT.D. Cook and D.L. DeMetsIntroduction to Statistical Process ControlP. QiuIntroduction to the Theory of Statistical InferenceH. Liero and S. ZwanzigLarge Sample Methods in StatisticsP.K. Sen and J. da Motta SingerLinear Algebra and Matrix Analysis for StatisticsS. Banerjee and A. RoyLogistic Regression ModelsJ.M. HilbeMarkov Chain Monte Carlo:Stochastic Simulation for Bayesian Inference, Second EditionD. Gamerman and H.F. LopesMultivariate Analysis of Variance and Repeated Measures: A Practical Approach for Behavioural ScientistsD.J. Hand and C.C. TaylorMultivariate Statistics: A Practical ApproachB. Flury and H. RiedwylMultivariate Survival Analysis and Competing RisksM. CrowderNonparametric Methods in Statistics with SAS ApplicationsO. KorostelevaPólya Urn ModelsH. MahmoudPractical Data Analysis for Designed ExperimentsB.S. YandellPractical Longitudinal Data AnalysisD.J. Hand and M. CrowderPractical Multivariate Analysis, Fifth EditionA. Afifi, S. May, and V.A. ClarkPractical Statistics for Medical ResearchD.G. AltmanA Primer on Linear ModelsJ.F. MonahanPrinciples of UncertaintyJ.B. KadaneProbability: Methods and MeasurementA. O’HaganProblem Solving: A Statistician’s Guide, Second EditionC. ChatfieldRandomization, Bootstrap and Monte Carlo Methods in Biology, Third EditionB.F.J. ManlyReadings in Decision AnalysisS. FrenchSampling Methodologies with ApplicationsP.S.R.S. RaoStationary Stochastic Processes: Theory and ApplicationsG. LindgrenStatistical Analysis of Reliability DataM.J. Crowder, A.C. Kimber, T.J. Sweeting, and R.L. SmithStatistical Methods for Spatial Data AnalysisO. Schabenberger and C.A. GotwayMathematical StatisticsK. KnightModeling and Analysis of Stochastic Systems, Second EditionV.G. KulkarniModelling Binary Data, Second EditionD. CollettModelling Survival Data in Medical Research, Second EditionD. Collett
Statistical Methods for SPC and TQMD. BissellStatistical Methods in Agriculture and Experimental Biology, Second Edition R. Mead, R.N. Curnow, and A.M. HastedStatistical Process Control: Theory and Practice, Third EditionG.B. Wetherill and D.W. BrownStatistical Theory: A Concise IntroductionF. Abramovich and Y. RitovStatistical Theory, Fourth EditionB.W. LindgrenStatistics for AccountantsS. LetchfordStatistics for EpidemiologyN.P. JewellStatistics in Research and Development, Second EditionR. CaulcuttStochastic Processes: An Introduction, Second EditionP.W. Jones and P. SmithSurvival Analysis Using S: Analysis of Time-to-Event DataM. Tableman and J.S. KimThe Theory of Linear ModelsB. JørgensenTime Series AnalysisH. MadsenTime Series: Modeling, Computation, and InferenceR. Prado and M. WestUnderstanding Advanced Statistical MethodsP.H. Westfall and K.S.S. HenningStatistics for Technology: A Course in Applied Statistics, Third EditionC. ChatfieldStatistics in Engineering: A Practical ApproachA.V. Metcalfe
Texts in Statistical ScienceBayesian Data AnalysisThird EditionAndrew Gelman John B. Carlin Hal S. Stern David B. Dunson Aki Vehtari Donald B. Rubin
CRC PressTaylor & Francis Group6000 Broken Sound Parkway NW, Suite 300 Boca Raton, FL 33487-2742© 2014 by Taylor & Francis Group, LLCCRC Press is an imprint of Taylor & Francis Group, an Informa businessNo claim to original U.S. Government works Version Date: 20131003International Standard Book Number-13: 978-1-4398-9820-8 (eBook - PDF)This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot assume responsibility for the valid- ity of all materials or the consequences of their use. The authors and publishers have attempted to trace the copyright holders of all material reproduced in this publication and apologize to copyright holders if permission to publish in this form has not been obtained. If any copyright material has not been acknowledged please write and let us know so we may rectify in any future reprint.Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or uti- lized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopy- ing, microfilming, and recording, or in any information storage or retrieval system, without written permission from the publishers.For permission to photocopy or use material electronically from this work, please access www.copyright.com (http:// www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For organizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for identification and explanation without intent to infringe.Visit the Taylor & Francis Web site at http://www.taylorandfrancis.comand the CRC Press Web site at http://www.crcpress.com
ContentsPreface xiiiPart I: Fundamentals of Bayesian Inference 11 Probability and inference 31.1 The three steps of Bayesian data analysis 31.2 General notation for statistical inference 41.3 Bayesian inference 61.4 Discrete probability examples: genetics and spell checking 81.5 Probability as a measure of uncertainty 111.6 Example of probability assignment: football point spreads 131.7 Example: estimating the accuracy of record linkage 161.8 Some useful results from probability theory 191.9 Computation and software 221.10 Bayesian inference in applied statistics 241.11 Bibliographic note 251.12 Exercises 272 Single-parameter models 292.1 Estimating a probability from binomial data 292.2 Posterior as compromise between data and prior information 322.3 Summarizing posterior inference 322.4 Informative prior distributions 342.5 Estimating a normal mean with known variance 392.6 Other standard single-parameter models 422.7 Example: informative prior distribution for cancer rates 472.8 Noninformative prior distributions 512.9 Weakly informative prior distributions 552.10 Bibliographic note 562.11 Exercises 573 Introduction to multiparameter models 633.1 Averaging over ‘nuisance parameters’ 633.2 Normal data with a noninformative prior distribution 643.3 Normal data with a conjugate prior distribution 673.4 Multinomial model for categorical data 693.5 Multivariate normal model with known variance 703.6 Multivariate normal with unknown mean and variance 723.7 Example: analysis of a bioassay experiment 743.8 Summary of elementary modeling and computation 783.9 Bibliographic note3.10 Exercises78 79vii
viii45CONTENTSAsymptotics and connections to non-Bayesian approaches 834.1 Normal approximations to the posterior distribution 834.2 Large-sample theory 874.3 Counterexamples to the theorems 894.4 Frequency evaluations of Bayesian inferences 914.5 Bayesian interpretations of other statistical methods 924.6 Bibliographic note 974.7 Exercises 98Hierarchical models 1015.1 Constructing a parameterized prior distribution 1025.2 Exchangeability and setting up hierarchical models 1045.3 Fully Bayesian analysis of conjugate hierarchical models 1085.4 Estimating exchangeable parameters from a normal model 1135.5 Example: parallel experiments in eight schools 1195.6 Hierarchical modeling applied to a meta-analysis 1245.7 Weakly informative priors for hierarchical variance parameters 1285.8 Bibliographic note 1325.9 Exercises 134Part II: Fundamentals of Bayesian Data Analysis 1396 Model checking 1416.1 The place of model checking in applied Bayesian statistics 1416.2 Do the inferences from the model make sense? 1426.3 Posterior predictive checking 1436.4 Graphical posterior predictive checks 1536.5 Model checking for the educational testing example 1596.6 Bibliographic note 1616.7 Exercises 1637 Evaluating, comparing, and expanding models 1657.1 Measures of predictive accuracy 1667.2 Information criteria and cross-validation 1697.3 Model comparison based on predictive performance 1787.4 Model comparison using Bayes factors 1827.5 Continuous model expansion 1847.6 Implicit assumptions and model expansion: an example 1877.7 Bibliographic note 1927.8 Exercises 1938 Modeling accounting for data collection 1978.1 Bayesian inference requires a model for data collection 1978.2 Data-collection models and ignorability 1998.3 Sample surveys 2058.4 Designed experiments 2148.5 Sensitivity and the role of randomization 2188.6 Observational studies 2208.7 Censoring and truncation 2248.8 Discussion 2298.9 Bibliographic note 2298.10 Exercises 230
CONTENTS ix9 Decision analysis 2379.1 Bayesian decision theory in different contexts 2379.2 Using regression predictions: incentives for telephone surveys 2399.3 Multistage decision making: medical screening 2459.4 Hierarchical decision analysis for radon measurement 2469.5 Personal vs. institutional decision analysis 2569.6 Bibliographic note 2579.7 Exercises 257Part III: Advanced Computation 25910 Introduction to Bayesian computation 26110.1 Numerical integration 261 10.2 Distributional approximations 262 10.3 Direct simulation and rejection sampling 263 10.4 Importance sampling 265 10.5 How many simulation draws are needed? 267 10.6 Computing environments 268 10.7 Debugging Bayesian computing 270 10.8 Bibliographic note 271 10.9 Exercises 27211 Basics of Markov chain simulation 27511.1 Gibbs sampler 276 11.2 Metropolis and Metropolis-Hastings algorithms 278 11.3 Using Gibbs and Metropolis as building blocks 280 11.4 Inference and assessing convergence 281 11.5 Effective number of simulation draws 286 11.6 Example: hierarchical normal model 288 11.7 Bibliographic note 291 11.8 Exercises 29112 Computationally efficient Markov chain simulation 29312.1 Efficient Gibbs samplers 293 12.2 Efficient Metropolis jumping rules 295 12.3 Further extensions to Gibbs and Metropolis 297 12.4 Hamiltonian Monte Carlo 300 12.5 Hamiltonian dynamics for a simple hierarchical model 305 12.6 Stan: developing a computing environment 307 12.7 Bibliographic note 308 12.8 Exercises 30913 Modal and distributional approximations 31113.1 Finding posterior modes 311 13.2 Boundary-avoiding priors for modal summaries 313 13.3 Normal and related mixture approximations 318 13.4 Finding marginal posterior modes using EM 320 13.5 Approximating conditional and marginal posterior densities 325 13.6 Example: hierarchical normal model (continued) 326 13.7 Variational inference 331 13.8 Expectation propagation 338 13.9 Other approximations 343
xCONTENTS345 348 34935135313.10 Unknown normalizing factors 13.11 Bibliographic note13.12 ExercisesPart IV: Regression Models14 Introduction to regression models14.1 Conditional modeling14.2 Bayesian analysis of the classical regression model14.3 Regression for causal inference: incumbency in congressional elections 358 14.4 Goals of regression analysis 364 14.5 Assembling the matrix of explanatory variables 365 14.6 Regularization and dimension reduction for multiple predictors 367 14.7 Unequal variances and correlations 369 14.8 Including numerical prior information 376 14.9 Bibliographic note 378 14.10 Exercises 37815 Hierarchical linear models 38115.1 Regression coefficients exchangeable in batches 382 15.2 Example: forecasting U.S. presidential elections 383 15.3 Interpreting a normal prior distribution as additional data 388 15.4 Varying intercepts and slopes 390 15.5 Computation: batching and transformation 392 15.6 Analysis of variance and the batching of coefficients 395 15.7 Hierarchical models for batches of variance components 398 15.8 Bibliographic note 400 15.9 Exercises 40216 Generalized linear models 40516.1 Standard generalized linear model likelihoods 406 16.2 Working with generalized linear models 407 16.3 Weakly informative priors for logistic regression 412 16.4 Example: hierarchical Poisson regression for police stops 420 16.5 Example: hierarchical logistic regression for political opinions 422 16.6 Models for multivariate and multinomial responses 423 16.7 Loglinear models for multivariate discrete data 428 16.8 Bibliographic note 431 16.9 Exercises 43217 Models for robust inference 43517.1 Aspects of robustness 435 17.2 Overdispersed versions of standard probability models 437 17.3 Posterior inference and computation 439 17.4 Robust inference and sensitivity analysis for the eight schools 441 17.5 Robust regression using t-distributed errors 444 17.6 Bibliographic note 445 17.7 Exercises 446353 354
CONTENTS xi18 Models for missing data 44918.1 Notation 449 18.2 Multiple imputation 451 18.3 Missing data in the multivariate normal and t models 454 18.4 Example: multiple imputation for a series of polls 456 18.5 Missing values with counted data 462 18.6 Example: an opinion poll in Slovenia 463 18.7 Bibliographic note 466 18.8 Exercises 467Part V: Nonlinear and Nonparametric Models 46919 Parametric nonlinear models 47119.1 Example: serial dilution assay 471 19.2 Example: population toxicokinetics 477 19.3 Bibliographic note 485 19.4 Exercises 48620 Basis function models 48720.1 Splines and weighted sums of basis functions 487 20.2 Basis selection and shrinkage of coefficients 490 20.3 Non-normal models and multivariate regression surfaces 494 20.4 Bibliographic note 498 20.5 Exercises 49821 Gaussian process models 50121.1 Gaussian process regression 501 21.2 Example: birthdays and birthdates 505 21.3 Latent Gaussian process models 510 21.4 Functional data analysis 512 21.5 Density estimation and regression 513 21.6 Bibliographic note 516 21.7 Exercises 51622 Finite mixture models 51922.1 Setting up and interpreting mixture models 519 22.2 Example: reaction times and schizophrenia 524 22.3 Label switching and posterior computation 533 22.4 Unspecified number of mixture components 536 22.5 Mixture models for classification and regression 539 22.6 Bibliographic note 542 22.7 Exercises 54323 Dirichlet process models 54523.1 Bayesian histograms 545 23.2 Dirichlet process prior distributions 546 23.3 Dirichlet process mixtures 549 23.4 Beyond density estimation 557 23.5 Hierarchical dependence 560 23.6 Density regression 568 23.7 Bibliographic note 571 23.8 Exercises 573
xii CONTENTSA Standard probability distributions 575A.1 Continuous distributions 575A.2 Discrete distributions 583A.3 Bibliographic note 584B Outline of proofs of limit theorems 585B.1 Bibliographic note 588C Computation in R and Stan 589C.1 Getting started with R and Stan 589C.2 Fitting a hierarchical model in Stan 589C.3 Direct simulation, Gibbs, and Metropolis in R 594C.4 Programming Hamiltonian Monte Carlo in R 601C.5 Further comments on computation 605C.6 Bibliographic note 606References 607 Author Index 641 Subject Index 649
PrefaceThis book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader’s previous experience in probability, statistics, and linear algebra should ideally have included strong computational components.To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, be- yond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods with- out first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book.Examples of real statistical analyses appear throughout the book, and we hope thereby to give an applied flavor to the entire development. Indeed, given the conceptual simplicity of the Bayesian approach, it is only in the intricacy of specific applications that novelty arises. Non-Bayesian approaches dominated statistical theory and practice for most of the last century, but the last few decades have seen a re-emergence of Bayesian methods. This has been driven more by the availability of new computational techniques than by what many would see as the theoretical and logical advantages of Bayesian thinking.In our treatment of Bayesian inference, we focus on practice rather than philosophy. We demonstrate our attitudes via examples that have arisen in the applied research of ourselves and others. Chapter 1 presents our views on the foundations of probability as empirical and measurable; see in particular Sections 1.4–1.7.Changes for the third editionThe biggest change for this new edition is the addition of Chapters 20–23 on nonparametric modeling. Other major changes include weakly informative priors in Chapters 2, 5, and elsewhere; boundary-avoiding priors in Chapter 13; an updated discussion of cross-validation and predictive information criteria in the new Chapter 7; improved convergence monitoring and effective sample size calculations for iterative simulation in Chapter 11; presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation in Chapters 12 and 13; and new and revised code in Appendix C. We have made other changes throughout.During the eighteen years since completing the first edition of Bayesian Data Analysis, we have worked on dozens of interesting applications which, for reasons of space, we are not able to add to this new edition. Many of these examples appear in our book, Data Analysisxiii
xiv PREFACEUsing Regression and Hierarchical/Multilevel Models, as well as in our published research articles.Online informationAdditional materials, including the data used in the examples, solutions to many of the end-of-chapter exercises, and any errors found after the book goes to press, are posted at http://www.stat.columbia.edu/∼gelman/book/. Feel free to send any comments to us directly.AcknowledgmentsWe thank many students, colleagues, and friends for comments and advice and also ac- knowledge the public funding that made much of this work possible.In particular, we thank Stephen Ansolabehere, Adriano Azevedo, Jarrett Barber, Richard Barker, Tom Belin, Michael Betancourt, Suzette Blanchard, Rob Calver, Brad Carlin, Bob Carpenter, Alicia Carriquiry, Samantha Cook, Alex Damour, Victor De Oliveira, Vince Dorie, David Draper, John Emerson, Steve Fienberg, Alex Franks, Byron Gajewski, Yuan- jun Gao, Daniel Gianola, Yuri Goegebeur, David Hammill, Chad Heilig, Matt Hoffman, Chuanpu Hu, Zaiying Huang, Shane Jensen, Yoon-Sook Jeon, Pasi Jylanki, Jay Kadane, Jouni Kerman, Gary King, Lucien Le Cam, Yew Jin Lim, Rod Little, Tom Little, Chuanhai Liu, Xuecheng Liu, Peter McCullagh, Mary Sara McPeek, Xiao-Li Meng, Baback Moghad- dam, Olivier Nimeskern, Peter Norvig, Ali Rahimi, Thomas Richardson, Christian Robert, Scott Schmidler, Matt Schofield, Andrea Siegel, Sandip Sinharay, Elizabeth Stuart, Andrew Swift, Eric Tassone, Francis Tuerlinckx, Iven Van Mechelen, Amos Waterland, Rob Weiss, Lo-Hua Yuan, and Alan Zaslavsky. We especially thank John Boscardin, Jessica Hwang, Daniel Lee, Phillip Price, and Radford Neal.This work was partially supported by research grants from the National Science Foun- dation, National Institutes of Health, Institute of Education Sciences, National Security Agency, Department of Energy, and Academy of Finland.Many of our examples have appeared in books and articles wtitten by ourselves and others, as we indicate in the bibliographic notes and exercises in the chapters where they appear.1Finally, we thank Caroline, Nancy, Hara, Amy, Ilona, and other family and friends for their love and support during the writing and revision of this book.1In particular: Figures 1.3–1.5 are adapted from the Journal of the American Statistical Association 90 (1995), pp. 696, 702, and 703, and are reprinted with permission of the American Statistical Association. Figures 2.6 and 2.7 come from Gelman, A., and Nolan, D., Teaching Statistics: A Bag of Tricks, Oxford University Press (1992), pp. 14 and 15, and are reprinted with permission of Oxford University Press. Figures 19.8–19.10 come from the Journal of the American Statistical Association 91 (1996), pp. 1407 and 1409, and are reprinted with permission of the American Statistical Association. Table 19.1 comes from Berry, D., Statistics: A Bayesian Perspective, first edition, copyright 1996 Wadsworth, a part of Cengage Learning, Inc. Reproduced by permission. www.cengage.com/permissions. Figures 18.1 and 18.2 come from the Journal of the American Statistical Association 93 (1998), pp. 851 and 853, and are reprinted with permission of the American Statistical Association. Figures 9.1–9.3 are adapted from the Journal of Business and Economic Statistics 21 (2003), pp. 219 and 223, and are reprinted with permission of the American Statistical Association. We thank Jack Taylor for the data used to produce Figure 23.4.
Part I: Fundamentals of Bayesian InferenceBayesian inference is the process of fitting a probability model to a set of data and sum- marizing the result by a probability distribution on the parameters of the model and on unobserved quantities such as predictions for new observations. In Chapters 1–3, we in- troduce several useful families of models and illustrate their application in the analysis of relatively simple data structures. Some mathematics arises in the analytical manipulation of the probability distributions, notably in transformation and integration in multiparameter problems. We differ somewhat from other introductions to Bayesian inference by emphasiz- ing stochastic simulation, and the combination of mathematical analysis and simulation, as general methods for summarizing distributions. Chapter 4 outlines the fundamental con- nections between Bayesian and other approaches to statistical inference. The early chapters focus on simple examples to develop the basic ideas of Bayesian inference; examples in which the Bayesian approach makes a practical difference relative to more traditional approaches begin to appear in Chapter 3. The major practical advantages of the Bayesian approach appear in Chapter 5, where we introduce hierarchical models, which allow the parameters of a prior, or population, distribution themselves to be estimated from data.1
